# -*- coding: utf-8 -*-
"""Predicting Equipment Failure and Scheduling Maintenance Proactively.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QRSo9CdWgG6ebbGGqUpaDujo6yWAZfgj
"""

# Importing necessary libraries
import pandas as pd
import psycopg2

# Setting up a connection to PostgreSQL database hosted on Google Cloud
conn = psycopg2.connect(
    host='host_name',
    dbname='database_name',
    user='username',
    password='password'
)

# Reading the CSV files
equipment_data = pd.read_csv('equipment_data.csv')
network_data = pd.read_csv('network_data.csv')
maintenance_data = pd.read_csv('maintenance_data.csv')

# Removing duplicates from the equipment and network sensor data
equipment_data.drop_duplicates(inplace=True)
network_data.drop_duplicates(inplace=True)

# Fixing missing data by filling NaN values with the mean value of the sensor reading
equipment_data['sensor_reading'].fillna(equipment_data['sensor_reading'].mean(), inplace=True)
network_data['sensor_reading'].fillna(network_data['sensor_reading'].mean(), inplace=True)

# Normalizing the data for consistency
equipment_data['date'] = pd.to_datetime(equipment_data['date'])
equipment_data['time'] = pd.to_datetime(equipment_data['time'])
network_data['date'] = pd.to_datetime(network_data['date'])
network_data['time'] = pd.to_datetime(network_data['time'])
maintenance_data['date'] = pd.to_datetime(maintenance_data['date'])
maintenance_data['time'] = pd.to_datetime(maintenance_data['time'])

# Aggregating the data to calculate useful metrics such as the total number of equipment failures, average time between failures, etc.
equipment_data_agg = equipment_data.groupby(['ID']).agg({'sensor_reading': 'mean', 'date': 'count', 'time': ['min', 'max']})
equipment_data_agg.columns = ['avg_sensor_reading', 'total_readings', 'first_reading', 'last_reading']
network_data_agg = network_data.groupby(['ID']).agg({'sensor_reading': 'mean', 'date': 'count', 'time': ['min', 'max']})
network_data_agg.columns = ['avg_sensor_reading', 'total_readings', 'first_reading', 'last_reading']

# Joining the equipment and network sensor data with the maintenance records based on the equipment ID
equipment_maintenance_data = pd.merge(equipment_data_agg, maintenance_data, on='ID', how='outer')

# Enriching the data by combining internal data with external data sources such as weather data or other publicly available datasets to gain additional insights.

# Loading the resulting data into the PostgreSQL database
equipment_data_agg.to_sql('equipment_data_agg', conn, if_exists='replace')
network_data_agg.to_sql('network_data_agg', conn, if_exists='replace')
equipment_maintenance_data.to_sql('equipment_maintenance_data', conn, if_exists='replace')